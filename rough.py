import nltk
from nltk.tokenize import word_tokenize


sample_text = "This is a test sentence."
tokens = word_tokenize(sample_text)
print(tokens)
